{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "%matplotlib inline"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "GridSearch with Census Data\n",
        "===========================\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "このノートブックでは、Fairlearn と Fairness ダッシュボードを使用して、Census データセットの予測値を生成する方法を示しています。このデータセットは分類問題で、32,000人の個人に関するデータが与えられた場合、その個人の年収が5万ドル以上か以下かを予測します。\n",
        "\n",
        "このノートでは、これをローン決定問題として扱うことにします。ラベルは、各個人が過去にローンを返済したかどうかを示していることにします。このデータを使って、以前見たことのない個人がローンを返済するかどうかを予測する予測器を訓練します。モデルの予測は、個人にローンを提供すべきかどうかを決定するために使われることを前提としています。\n",
        "\n",
        "まず、公平性を意識していない予測器を学習し、それが「デモグラフィック・パリティ」と呼ばれる特定の公平性の概念の下で、不公平な決定をもたらすことを示します。次に、Fairlearnパッケージの`GridSearch`{.sourceCode}アルゴリズムを適用することで、不公平感を軽減します。\n",
        "\n",
        "> This notebook shows how to use Fairlearn and the Fairness dashboard to generate predictors for the Census dataset. This dataset is a classification problem - given a range of data about 32,000 individuals, predict whether their annual income is above or below fifty thousand\n",
        "> dollars per year.\n",
        ">\n",
        "> For the purposes of this notebook, we shall treat this as a loan decision problem. We will pretend that the label indicates whether or not each individual repaid a loan in the past. We will use the data to train a predictor to predict whether previously unseen individuals will repay a loan or not. The assumption is that the model predictions are used to decide whether an individual should be offered a loan.\n",
        ">\n",
        "> We will first train a fairness-unaware predictor and show that it leads to unfair decisions under a specific notion of fairness called *demographic parity*. We then mitigate unfairness by applying the `GridSearch`{.sourceCode} algorithm from the Fairlearn package."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and preprocess the data set\n",
        "================================\n",
        "\n",
        "fairlearn.datasetsのfetch_adult関数を使って、データセットをダウンロードします。まず、使用する様々なモジュールをインポートします。\n",
        "\n",
        "`FairlearnDashboard`{.sourceCode}はFairlearnの一部として開発されなくなりました。ウィジェット自体は[the raiwidgets package](https://pypi.org/project/raiwidgets/)に移動しました。Fairlearnでは、既存の機能の一部を`matplotlib`{.sourceCode}ベースのビジュアライゼーションで提供します。\n",
        "\n",
        "> We download the data set using fetch\\_adult function in fairlearn.datasets. We start by importing the various modules we're going to use:\n",
        ">\n",
        "> > **note**\n",
        "> >\n",
        "> > The `FairlearnDashboard`{.sourceCode} is no longer being developed as part of Fairlearn. The widget itself has been moved to [the raiwidgets package](https://pypi.org/project/raiwidgets/). Fairlearn will provide some of the existing functionality through `matplotlib`{.sourceCode}-based visualizations."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from fairlearn.reductions import GridSearch\n",
        "from fairlearn.reductions import DemographicParity, ErrorRate\n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "import pandas as pd"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "source": [
        "from raiwidgets import FairnessDashboard\n",
        "FairlearnDashboard = FairnessDashboard"
      ],
      "outputs": [],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "fairlearn.datasetsを使って、データの読み込みと検査を行うことができます。\n",
        "\n",
        "> We can now load and inspect the data by using the fairlearn.datasets module:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "data = fetch_openml(data_id=1590, as_frame=True)\n",
        "X_raw = data.data\n",
        "Y = (data.target == '>50K') * 1\n",
        "X_raw"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        age     workclass    fnlwgt     education  education-num  \\\n",
              "0      25.0       Private  226802.0          11th            7.0   \n",
              "1      38.0       Private   89814.0       HS-grad            9.0   \n",
              "2      28.0     Local-gov  336951.0    Assoc-acdm           12.0   \n",
              "3      44.0       Private  160323.0  Some-college           10.0   \n",
              "4      18.0           NaN  103497.0  Some-college           10.0   \n",
              "...     ...           ...       ...           ...            ...   \n",
              "48837  27.0       Private  257302.0    Assoc-acdm           12.0   \n",
              "48838  40.0       Private  154374.0       HS-grad            9.0   \n",
              "48839  58.0       Private  151910.0       HS-grad            9.0   \n",
              "48840  22.0       Private  201490.0       HS-grad            9.0   \n",
              "48841  52.0  Self-emp-inc  287927.0       HS-grad            9.0   \n",
              "\n",
              "           marital-status         occupation relationship   race     sex  \\\n",
              "0           Never-married  Machine-op-inspct    Own-child  Black    Male   \n",
              "1      Married-civ-spouse    Farming-fishing      Husband  White    Male   \n",
              "2      Married-civ-spouse    Protective-serv      Husband  White    Male   \n",
              "3      Married-civ-spouse  Machine-op-inspct      Husband  Black    Male   \n",
              "4           Never-married                NaN    Own-child  White  Female   \n",
              "...                   ...                ...          ...    ...     ...   \n",
              "48837  Married-civ-spouse       Tech-support         Wife  White  Female   \n",
              "48838  Married-civ-spouse  Machine-op-inspct      Husband  White    Male   \n",
              "48839             Widowed       Adm-clerical    Unmarried  White  Female   \n",
              "48840       Never-married       Adm-clerical    Own-child  White    Male   \n",
              "48841  Married-civ-spouse    Exec-managerial         Wife  White  Female   \n",
              "\n",
              "       capital-gain  capital-loss  hours-per-week native-country  \n",
              "0               0.0           0.0            40.0  United-States  \n",
              "1               0.0           0.0            50.0  United-States  \n",
              "2               0.0           0.0            40.0  United-States  \n",
              "3            7688.0           0.0            40.0  United-States  \n",
              "4               0.0           0.0            30.0  United-States  \n",
              "...             ...           ...             ...            ...  \n",
              "48837           0.0           0.0            38.0  United-States  \n",
              "48838           0.0           0.0            40.0  United-States  \n",
              "48839           0.0           0.0            40.0  United-States  \n",
              "48840           0.0           0.0            20.0  United-States  \n",
              "48841       15024.0           0.0            40.0  United-States  \n",
              "\n",
              "[48842 rows x 14 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>workclass</th>\n",
              "      <th>fnlwgt</th>\n",
              "      <th>education</th>\n",
              "      <th>education-num</th>\n",
              "      <th>marital-status</th>\n",
              "      <th>occupation</th>\n",
              "      <th>relationship</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>capital-gain</th>\n",
              "      <th>capital-loss</th>\n",
              "      <th>hours-per-week</th>\n",
              "      <th>native-country</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>25.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>226802.0</td>\n",
              "      <td>11th</td>\n",
              "      <td>7.0</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>38.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>89814.0</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Farming-fishing</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>28.0</td>\n",
              "      <td>Local-gov</td>\n",
              "      <td>336951.0</td>\n",
              "      <td>Assoc-acdm</td>\n",
              "      <td>12.0</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Protective-serv</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>44.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>160323.0</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>Husband</td>\n",
              "      <td>Black</td>\n",
              "      <td>Male</td>\n",
              "      <td>7688.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>18.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>103497.0</td>\n",
              "      <td>Some-college</td>\n",
              "      <td>10.0</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48837</th>\n",
              "      <td>27.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>257302.0</td>\n",
              "      <td>Assoc-acdm</td>\n",
              "      <td>12.0</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Tech-support</td>\n",
              "      <td>Wife</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>38.0</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48838</th>\n",
              "      <td>40.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>154374.0</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Machine-op-inspct</td>\n",
              "      <td>Husband</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48839</th>\n",
              "      <td>58.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>151910.0</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Widowed</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Unmarried</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48840</th>\n",
              "      <td>22.0</td>\n",
              "      <td>Private</td>\n",
              "      <td>201490.0</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Never-married</td>\n",
              "      <td>Adm-clerical</td>\n",
              "      <td>Own-child</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48841</th>\n",
              "      <td>52.0</td>\n",
              "      <td>Self-emp-inc</td>\n",
              "      <td>287927.0</td>\n",
              "      <td>HS-grad</td>\n",
              "      <td>9.0</td>\n",
              "      <td>Married-civ-spouse</td>\n",
              "      <td>Exec-managerial</td>\n",
              "      <td>Wife</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>15024.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>United-States</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>48842 rows × 14 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ここでは、各個人の性別をセンシティブな特徴（0が女性、1が男性を表す）として扱い、この特別なケースでは、この特徴を分離してメインデータから削除します。次に、標準的なデータの前処理を行い、MLアルゴリズムに適した形式に変換します。\n",
        "\n",
        "> We are going to treat the sex of each individual as a sensitive feature (where 0 indicates female and 1 indicates male), and in this particular case we are going separate this feature out and drop it from the main data. We then perform some standard data preprocessing steps to convert the data into a format suitable for the ML algorithms\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "source": [
        "A = X_raw[\"sex\"]\n",
        "X = X_raw.drop(labels=['sex'], axis=1)\n",
        "X = pd.get_dummies(X)\n",
        "\n",
        "sc = StandardScaler()\n",
        "X_scaled = sc.fit_transform(X)\n",
        "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "\n",
        "le = LabelEncoder()\n",
        "Y = le.fit_transform(Y)"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "最後に、データをトレーニングセットとテストセットに分けます。\n",
        "\n",
        "> Finally, we split the data into training and test sets:\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "source": [
        "X_train, X_test, Y_train, Y_test, A_train, A_test = train_test_split(X_scaled,\n",
        "                                                                     Y,\n",
        "                                                                     A,\n",
        "                                                                     test_size=0.2,\n",
        "                                                                     random_state=0,\n",
        "                                                                     stratify=Y)\n",
        "\n",
        "# Work around indexing bug\n",
        "X_train = X_train.reset_index(drop=True)\n",
        "A_train = A_train.reset_index(drop=True)\n",
        "X_test = X_test.reset_index(drop=True)\n",
        "A_test = A_test.reset_index(drop=True)"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training a fairness-unaware predictor\n",
        "=====================================\n",
        "\n",
        "Fairlearnの効果を示すために、まず公平性を取り入れていない標準的なML予測器を訓練します。デモのスピードを上げるために、シンプルなsklearn.linear\\_model.LogisticRegressionクラスを使用します。\n",
        "\n",
        "> To show the effect of Fairlearn we will first train a standard ML predictor that does not incorporate fairness. For speed of demonstration, we use the simple sklearn.linear\\_model.LogisticRegression class:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "unmitigated_predictor = LogisticRegression(solver='liblinear', fit_intercept=True)\n",
        "\n",
        "unmitigated_predictor.fit(X_train, Y_train)"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(solver='liblinear')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "この予測値をFairnessダッシュボードに読み込み、その公平性を評価することができます。\n",
        "\n",
        "> We can load this predictor into the Fairness dashboard, and assess its fairness:\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "source": [
        "FairlearnDashboard(sensitive_features=A_test,\n",
        "                  #  sensitive_feature_names=['sex'],\n",
        "                   y_true=Y_test,\n",
        "                   y_pred={\"unmitigated\": unmitigated_predictor.predict(X_test)})"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fairness started at http://localhost:5000\n"
          ]
        }
      ],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "正確さの格差を見ると、男性は女性の約3倍の誤差があることがわかります。さらに興味深いのは、機会の格差で、男性は女性の3倍の割合でローンを提供されています。\n",
        "\n",
        "訓練データからこの特徴を削除したにもかかわらず、予測器は依然として性別によって差別されています。これは、予測器をフィットさせる際に敏感な特徴を無視するだけでは、不公平感が解消されないことを示しています。一般的に、除去された特徴と相関のある他の特徴が十分にあり、差別的な影響をもたらすことになります。\n",
        "\n",
        "> Looking at the disparity in accuracy, we see that males have an error about three times greater than the females. More interesting is the disparity in opportunity - males are offered loans at three times the rate of females.\n",
        "> \n",
        "> Despite the fact that we removed the feature from the training data, our predictor still discriminates based on sex. This demonstrates that simply ignoring a sensitive feature when fitting a predictor rarely eliminates unfairness. There will generally be enough other features correlated with the removed feature to lead to disparate impact."
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mitigation with GridSearch\n",
        "==========================\n",
        "\n",
        "fairlearn.reducations.GridSearchクラスは、[Agarwal et al.2018](https://arxiv.org/abs/1803.02453)のexponentiated gradient reductionの簡易版を実装しています。ユーザーは標準的なML推定量を供給しますが、これはブラックボックスとして扱われます。GridSearchは、再ラベル化と再重み付けのシーケンスを生成することで動作し、それぞれについて予測器を訓練します。\n",
        "\n",
        "この例では、公平性の指標として、（性別という敏感な特徴を持つ）人口学的平準化を指定します。人口統計学的平準化とは、個人が敏感なクラスのメンバーシップとは無関係に機会を提供される（この例ではローンが承認される）ことを必要とします（すなわち、女性と男性が同じ割合でローンを提供されるべきです）。ここでは単純化のためにこの指標を使用していますが、一般的には適切な公平性の指標は明らかではありません。\n",
        "\n",
        "> The fairlearn.reductions.GridSearch class implements a simplified version of the exponentiated gradient reduction of [Agarwal et al.  2018](https://arxiv.org/abs/1803.02453). The user supplies a standard ML estimator, which is treated as a blackbox. GridSearch works by generating a sequence of relabellings and reweightings, and trains a predictor for each.\n",
        ">\n",
        "> For this example, we specify demographic parity (on the sensitive feature of sex) as the fairness metric. Demographic parity requires that individuals are offered the opportunity (are approved for a loan in this example) independent of membership in the sensitive class (i.e., females and males should be offered loans at the same rate). We are using this metric for the sake of simplicity; in general, the appropriate fairness metric will not be obvious.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "source": [
        "sweep = GridSearch(LogisticRegression(solver='liblinear', fit_intercept=True),\n",
        "                   constraints=DemographicParity(),\n",
        "                   grid_size=71)"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "我々のアルゴリズムは，`fit()`{.sourceCode}と`predict()`{.sourceCode}メソッドを提供しており，Pythonの他のMLパッケージと同様の動作をします．ただし，`fit()`{.sourceCode}には2つの追加の引数を指定する必要があります．すなわち，敏感な特徴ラベルの列と，今回のスイープで生成する予測子の数です．\n",
        "\n",
        "fit()`{.sourceCode}が完了した後， fairlearn.reducations.GridSearchオブジェクトから予測子のフルセットを抽出します．\n",
        "\n",
        "> Our algorithms provide `fit()`{.sourceCode} and `predict()`{.sourceCode} methods, so they behave in a similar manner to other ML packages in Python. We do however have to specify two extra arguments to `fit()`{.sourceCode} - the column of sensitive feature labels, and also the number of predictors to generate in our sweep.\n",
        ">\n",
        "> After `fit()`{.sourceCode} completes, we extract the full set of predictors from the fairlearn.reductions.GridSearch object.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "source": [
        "sweep.fit(X_train, Y_train,\n",
        "          sensitive_features=A_train)\n",
        "\n",
        "predictors = sweep.predictors_"
      ],
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-10-cb592bed5a23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m sweep.fit(X_train, Y_train,\n\u001b[0m\u001b[1;32m      2\u001b[0m           sensitive_features=A_train)\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpredictors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msweep\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictors_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/fairlearn/reductions/_grid_search/grid_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0mlambda_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Obtaining weights\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 165\u001b[0;31m             \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstraints\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigned_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlambda_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobjective_in_the_span\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m                 \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mobjective\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigned_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/fairlearn/reductions/_moments/utility_parity.py\u001b[0m in \u001b[0;36msigned_weights\u001b[0;34m(self, lambda_vec)\u001b[0m\n\u001b[1;32m    254\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprob_group_event\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0madjust\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlambda_event\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlambda_group_event\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m         signed_weights = self.tags.apply(\n\u001b[0m\u001b[1;32m    257\u001b[0m             \u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_EVENT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0madjust\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_EVENT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_GROUP_ID\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         )\n",
            "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, raw, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   7766\u001b[0m             \u001b[0mkwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7767\u001b[0m         )\n\u001b[0;32m-> 7768\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   7769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   7770\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mna_action\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m         \u001b[0mresults\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mres_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0;31m# ignore SettingWithCopy here in case the user mutates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                 \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mABCSeries\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m                     \u001b[0;31m# If we have a view on v, we need to make a copy because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/.local/lib/python3.8/site-packages/fairlearn/reductions/_moments/utility_parity.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0madjust\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlambda_event\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlambda_group_event\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         signed_weights = self.tags.apply(\n\u001b[0;32m--> 257\u001b[0;31m             \u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_EVENT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0madjust\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_EVENT\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_GROUP_ID\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m         )\n\u001b[1;32m    259\u001b[0m         \u001b[0mutility_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutilities\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    857\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m                 \u001b[0;31m# For labels that don't resolve as scalars like tuples and frozensets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m    959\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    962\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_values_for_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    963\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/pandas/core/indexes/multi.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method)\u001b[0m\n\u001b[1;32m   2859\u001b[0m         \u001b[0mhash\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2861\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0m_maybe_to_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2862\u001b[0m             \u001b[0;34m\"\"\"convert integer indexer to boolean mask or slice if possible\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2863\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "これらの予測因子を今すぐFairnessダッシュボードにロードすることができます。しかし、プロットは、その数のためにやや混乱するでしょう。このケースでは、誤差-視差空間で他のものに支配されている予測子を掃引から取り除きます（視差は敏感な特徴についてのみ計算されることに注意してください；他の潜在的に敏感な特徴は軽減されません）。一般的には，（与えられた敏感な特徴の）誤差と視差の厳密な最適化を超えた他の考慮事項があるので，これをしたくないかもしれません。\n",
        "\n",
        "> We could load these predictors into the Fairness dashboard now. However, the plot would be somewhat confusing due to their number. In this case, we are going to remove the predictors which are dominated in the error-disparity space by others from the sweep (note that the disparity will only be calculated for the sensitive feature; other potentially sensitive features will not be mitigated). In general, one might not want to do this, since there may be other considerations beyond the strict optimization of error and disparity (of the given sensitive feature).\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "errors, disparities = [], []\n",
        "for m in predictors:\n",
        "    def classifier(X): return m.predict(X)\n",
        "\n",
        "    error = ErrorRate()\n",
        "    error.load_data(X_train, pd.Series(Y_train), sensitive_features=A_train)\n",
        "    disparity = DemographicParity()\n",
        "    disparity.load_data(X_train, pd.Series(Y_train), sensitive_features=A_train)\n",
        "\n",
        "    errors.append(error.gamma(classifier)[0])\n",
        "    disparities.append(disparity.gamma(classifier).max())\n",
        "\n",
        "all_results = pd.DataFrame({\"predictor\": predictors, \"error\": errors, \"disparity\": disparities})\n",
        "\n",
        "non_dominated = []\n",
        "for row in all_results.itertuples():\n",
        "    errors_for_lower_or_eq_disparity = all_results[\"error\"][all_results[\"disparity\"] <= row.disparity]\n",
        "    if row.error <= errors_for_lower_or_eq_disparity.min():\n",
        "        non_dominated.append(row.predictor)"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "最後に、支配的なモデルを「Fairness」ダッシュボードに入れて、緩和されていないモデルと一緒に表示することができます。\n",
        "\n",
        "> Finally, we can put the dominant models into the Fairness dashboard, along with the unmitigated model.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "dashboard_predicted = {\"unmitigated\": unmitigated_predictor.predict(X_test)}\n",
        "for i in range(len(non_dominated)):\n",
        "    key = \"dominant_model_{0}\".format(i)\n",
        "    value = non_dominated[i].predict(X_test)\n",
        "    dashboard_predicted[key] = value\n",
        "\n",
        "\n",
        "FairlearnDashboard(sensitive_features=A_test, sensitive_feature_names=['sex'],\n",
        "                   y_true=Y_test,\n",
        "                   y_pred=dashboard_predicted)"
      ],
      "outputs": [],
      "metadata": {
        "collapsed": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "パレートフロントが形成されているのがわかります - 予測における精度と格差の間の最適なトレードオフを表す予測子のセットです。理想的なケースでは、(1,0)に予測値があります - 完全に正確で、（センシティブな特徴である \"性 \"に関して）人口学的なパリティのもとで不公平感がありません。パレートフロントは、我々のデータと推定量の選択に基づいて、この理想に最も近づくことができることを表しています。軸の範囲に注意してください - 視差軸は精度よりも多くの値をカバーしているので、精度の損失が小さくても視差を大幅に減らすことができます。\n",
        "\n",
        "プロット上の個々のモデルをクリックすると、視差と精度の測定基準をより詳細に調べることができます。実際の例では、関連するビジネス上の制約を考慮して、精度と視差の間の最良のトレードオフを示すモデルを選ぶことになるでしょう。\n",
        "\n",
        "> We see a Pareto front forming - the set of predictors which represent optimal tradeoffs between accuracy and disparity in predictions. In the ideal case, we would have a predictor at (1,0) - perfectly accurate and without any unfairness under demographic parity (with respect to the sensitive feature \"sex\"). The Pareto front represents the closest we can come to this ideal based on our data and choice of estimator. Note the range of the axes - the disparity axis covers more values than the accuracy, so we can reduce disparity substantially for a small loss in accuracy.\n",
        ">\n",
        "> By clicking on individual models on the plot, we can inspect their metrics for disparity and accuracy in greater detail. In a real example, we would then pick the model which represented the best trade-off between accuracy and disparity given the relevant business constraints.\n"
      ],
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 参考になるサイト\n",
        "\n",
        "- [機械学習の公平性 (プレビュー) - Azure Machine Learning | Microsoft Docs](https://docs.microsoft.com/ja-jp/azure/machine-learning/concept-fairness-ml \"機械学習の公平性 (プレビュー) - Azure Machine Learning | Microsoft Docs\")\n",
        "- [Azure Machine Learning Studioで使って理解を深めるResponsible AI (Part 2) – Fairlearn&lt;公平性&gt;編 – #Azure #AzureMachineLearning | DevelopersIO](https://dev.classmethod.jp/articles/mrmo-azure-ai-ml-fairlearn-20210408/ \"Azure Machine Learning Studioで使って理解を深めるResponsible AI (Part 2) – Fairlearn&lt;公平性&gt;編 – #Azure #AzureMachineLearning | DevelopersIO\")"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.8.8 64-bit ('base': conda)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "interpreter": {
      "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}